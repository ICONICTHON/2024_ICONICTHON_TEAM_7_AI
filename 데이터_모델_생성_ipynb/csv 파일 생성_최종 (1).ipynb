{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP6VKCyP8p5DVA1DcUb5ClT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qom8RBEnc1d6","executionInfo":{"status":"ok","timestamp":1731578951696,"user_tz":-540,"elapsed":4305,"user":{"displayName":"남민주","userId":"08247165472229416741"}},"outputId":"0a236a5c-c246-4c77-8cea-76122b834577"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n","Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"]}],"source":["#pip install pandas\n"]},{"cell_type":"code","source":["#pip install mysql-connector-python\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EiuxE9w4n212","executionInfo":{"status":"ok","timestamp":1731578955281,"user_tz":-540,"elapsed":3587,"user":{"displayName":"남민주","userId":"08247165472229416741"}},"outputId":"c93210aa-7c87-49e0-ecbe-386fc158ed68"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: mysql-connector-python in /usr/local/lib/python3.10/dist-packages (9.1.0)\n"]}]},{"cell_type":"code","source":["#pip install chardet\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zYu51Zn0odaM","executionInfo":{"status":"ok","timestamp":1731578962231,"user_tz":-540,"elapsed":3267,"user":{"displayName":"남민주","userId":"08247165472229416741"}},"outputId":"dccf42ea-f30b-4149-c206-5a0af64c639f"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (5.2.0)\n"]}]},{"cell_type":"code","source":["import re\n","import pandas as pd\n","import chardet\n","\n","# SQL dump 파일 경로\n","sql_file_path = '/content/mqtt_server_tvoc.sql'\n","\n","# 파일의 인코딩 자동 탐지\n","with open(sql_file_path, 'rb') as file:\n","    raw_data = file.read()\n","    result = chardet.detect(raw_data)\n","    encoding = result['encoding']\n","\n","# SQL dump 파일을 자동으로 감지된 인코딩 방식으로 읽기\n","with open(sql_file_path, 'r', encoding=encoding) as file:\n","    sql_script = file.read()\n","\n","# 'INSERT INTO' 구문을 찾기 위한 정규 표현식\n","insert_pattern = r\"INSERT INTO `sensor_data_tvoc` VALUES \\((.*?)\\);\"\n","\n","# 모든 INSERT 구문을 추출\n","matches = re.findall(insert_pattern, sql_script)\n","\n","# 'sensor_data_tvoc' 테이블에 대한 데이터 저장\n","data = []\n","\n","# 각 매치된 값에 대해 처리\n","for match in matches:\n","    # 개별 레코드를 나누기 위해 \"),\" 기준으로 분리 후 괄호 제거\n","    records = re.findall(r\"\\(([^)]+)\\)\", match)\n","    for record in records:\n","        # 개별 값들을 분리하여 리스트로 추가\n","        row = [x.strip().strip(\"'\") for x in record.split(',')]\n","        data.append(row)\n","\n","# 데이터 프레임 생성 및 CSV 파일로 저장\n","columns = ['id', 'sensor_id', 'timestamp', 'value']\n","df = pd.DataFrame(data, columns=columns)\n","csv_file_path = '/content/sensor_data_tvoc_data.csv'\n","df.to_csv(csv_file_path, index=False, encoding='utf-8')\n","\n","print(f\"sensor_data_tvoc CSV 파일이 성공적으로 저장되었습니다: {csv_file_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zLi-ekpa1Gz5","executionInfo":{"status":"ok","timestamp":1731580297859,"user_tz":-540,"elapsed":148211,"user":{"displayName":"남민주","userId":"08247165472229416741"}},"outputId":"c166bba5-ba86-4d4f-d7a5-8dfbc7573ad0"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["sensor_data_tvoc CSV 파일이 성공적으로 저장되었습니다: /content/sensor_data_tvoc_data.csv\n"]}]},{"cell_type":"code","source":["import re\n","import pandas as pd\n","import chardet\n","\n","# SQL dump 파일 경로\n","sql_file_path = '/content/mqtt_server_tvoc.sql'\n","\n","# 파일의 인코딩 자동 탐지\n","with open(sql_file_path, 'rb') as file:\n","    raw_data = file.read()\n","    result = chardet.detect(raw_data)\n","    encoding = result['encoding']\n","\n","# SQL dump 파일을 자동으로 감지된 인코딩 방식으로 읽기\n","with open(sql_file_path, 'r', encoding=encoding) as file:\n","    sql_script = file.read()\n","\n","# 'INSERT INTO' 구문을 찾기 위한 정규 표현식\n","insert_pattern = r\"INSERT INTO `sensor_data_tvoc` VALUES \\((.*?)\\);\"\n","\n","# 모든 INSERT 구문을 추출\n","matches = re.findall(insert_pattern, sql_script)\n","\n","# 'sensor_data_tvoc' 테이블에 대한 데이터 저장\n","data = []\n","\n","# 각 매치된 값에 대해 처리\n","for match in matches:\n","    # 개별 레코드를 나누기 위해 \"),\" 기준으로 분리 후 괄호 제거\n","    records = re.findall(r\"\\(([^)]+)\\)\", match)\n","    for record in records:\n","        # 개별 값들을 분리하여 리스트로 추가\n","        row = [x.strip().strip(\"'\") for x in record.split(',')]\n","        data.append(row)\n","\n","# 데이터 프레임 생성 및 CSV 파일로 저장\n","columns = ['id', 'sensor_id', 'timestamp', 'value']\n","df = pd.DataFrame(data, columns=columns)\n","csv_file_path = '/content/sensor_data_tvoc_data.csv'\n","df.to_csv(csv_file_path, index=False, encoding='utf-8')\n","\n","print(f\"sensor_data_tvoc CSV 파일이 성공적으로 저장되었습니다: {csv_file_path}\")\n"],"metadata":{"id":"UbR5mI6xOEbm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re\n","import pandas as pd\n","import chardet\n","\n","# SQL dump 파일 경로\n","sql_file_path = '/content/mqtt_server_temperature.sql'\n","\n","# 파일의 인코딩 자동 탐지\n","with open(sql_file_path, 'rb') as file:\n","    raw_data = file.read()\n","    result = chardet.detect(raw_data)\n","    encoding = result['encoding']\n","\n","# SQL dump 파일을 자동으로 감지된 인코딩 방식으로 읽기\n","with open(sql_file_path, 'r', encoding=encoding) as file:\n","    sql_script = file.read()\n","\n","# 'INSERT INTO' 구문을 찾기 위한 정규 표현식\n","insert_pattern = r\"INSERT INTO `sensor_data_temperature` VALUES \\((.*?)\\);\"\n","\n","# 모든 INSERT 구문을 추출\n","matches = re.findall(insert_pattern, sql_script)\n","\n","# 'sensor_data_temperature' 테이블에 대한 데이터 저장\n","data = []\n","\n","# 각 매치된 값에 대해 처리\n","for match in matches:\n","    # 개별 레코드를 나누기 위해 \"),\" 기준으로 분리 후 괄호 제거\n","    records = re.findall(r\"\\(([^)]+)\\)\", match)\n","    for record in records:\n","        # 개별 값들을 분리하여 리스트로 추가\n","        row = [x.strip().strip(\"'\") for x in record.split(',')]\n","        data.append(row)\n","\n","# 데이터 프레임 생성 및 CSV 파일로 저장\n","columns = ['id', 'sensor_id', 'timestamp', 'value']  # 적절한 열 이름으로 수정 가능\n","df = pd.DataFrame(data, columns=columns)\n","csv_file_path = '/content/sensor_data_temperature_data.csv'\n","df.to_csv(csv_file_path, index=False, encoding='utf-8')\n","\n","print(f\"sensor_data_temperature CSV 파일이 성공적으로 저장되었습니다: {csv_file_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AvF8P54aOEg2","executionInfo":{"status":"ok","timestamp":1731580401975,"user_tz":-540,"elapsed":52270,"user":{"displayName":"남민주","userId":"08247165472229416741"}},"outputId":"f55a273c-57cf-4faa-9aaa-428a847a2181"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["sensor_data_temperature CSV 파일이 성공적으로 저장되었습니다: /content/sensor_data_temperature_data.csv\n"]}]},{"cell_type":"code","source":["import re\n","import pandas as pd\n","import chardet\n","\n","# SQL dump 파일 경로\n","sql_file_path = '/content/mqtt_server_pm2_5.sql'\n","\n","# 파일의 인코딩 자동 탐지\n","with open(sql_file_path, 'rb') as file:\n","    raw_data = file.read()\n","    result = chardet.detect(raw_data)\n","    encoding = result['encoding']\n","\n","# SQL dump 파일을 자동으로 감지된 인코딩 방식으로 읽기\n","with open(sql_file_path, 'r', encoding=encoding) as file:\n","    sql_script = file.read()\n","\n","# 'INSERT INTO' 구문을 찾기 위한 정규 표현식\n","insert_pattern = r\"INSERT INTO `sensor_data_pm2_5mass_concentration` VALUES \\((.*?)\\);\"\n","\n","# 모든 INSERT 구문을 추출\n","matches = re.findall(insert_pattern, sql_script)\n","\n","# 'sensor_data_pm2_5mass_concentration' 테이블에 대한 데이터 저장\n","data = []\n","\n","# 각 매치된 값에 대해 처리\n","for match in matches:\n","    # 개별 레코드를 나누기 위해 \"),\" 기준으로 분리 후 괄호 제거\n","    records = re.findall(r\"\\(([^)]+)\\)\", match)\n","    for record in records:\n","        # 개별 값들을 분리하여 리스트로 추가\n","        row = [x.strip().strip(\"'\") for x in record.split(',')]\n","        data.append(row)\n","\n","# 데이터 프레임 생성 및 CSV 파일로 저장\n","columns = ['id', 'sensor_id', 'timestamp', 'value']  # 적절한 열 이름으로 수정 가능\n","df = pd.DataFrame(data, columns=columns)\n","csv_file_path = '/content/sensor_data_pm2_5_data.csv'\n","df.to_csv(csv_file_path, index=False, encoding='utf-8')\n","\n","print(f\"sensor_data_pm2_5mass_concentration CSV 파일이 성공적으로 저장되었습니다: {csv_file_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IxfpwA4QOElp","executionInfo":{"status":"ok","timestamp":1731580623006,"user_tz":-540,"elapsed":7129,"user":{"displayName":"남민주","userId":"08247165472229416741"}},"outputId":"15f4db00-1586-4a97-8c71-c7f834dca489"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["sensor_data_pm2_5mass_concentration CSV 파일이 성공적으로 저장되었습니다: /content/sensor_data_pm2_5_data.csv\n"]}]},{"cell_type":"code","source":["import re\n","import pandas as pd\n","import chardet\n","\n","# SQL dump 파일 경로\n","sql_file_path = '/content/mqtt_server_noise.sql'\n","\n","# 파일의 인코딩 자동 탐지\n","with open(sql_file_path, 'rb') as file:\n","    raw_data = file.read()\n","    result = chardet.detect(raw_data)\n","    encoding = result['encoding']\n","\n","# SQL dump 파일을 자동으로 감지된 인코딩 방식으로 읽기\n","with open(sql_file_path, 'r', encoding=encoding) as file:\n","    sql_script = file.read()\n","\n","# 'INSERT INTO' 구문을 찾기 위한 정규 표현식\n","insert_pattern = r\"INSERT INTO `sensor_data_ambient_noise` VALUES \\((.*?)\\);\"\n","\n","# 모든 INSERT 구문을 추출\n","matches = re.findall(insert_pattern, sql_script)\n","\n","# 'sensor_data_ambient_noise' 테이블에 대한 데이터 저장\n","data = []\n","\n","# 각 매치된 값에 대해 처리\n","for match in matches:\n","    # 개별 레코드를 나누기 위해 \"),\" 기준으로 분리 후 괄호 제거\n","    records = re.findall(r\"\\(([^)]+)\\)\", match)\n","    for record in records:\n","        # 개별 값들을 분리하여 리스트로 추가\n","        row = [x.strip().strip(\"'\") for x in record.split(',')]\n","        data.append(row)\n","\n","# 데이터 프레임 생성 및 CSV 파일로 저장\n","columns = ['id', 'sensor_id', 'timestamp', 'value']  # 적절한 열 이름으로 수정 가능\n","df = pd.DataFrame(data, columns=columns)\n","csv_file_path = '/content/sensor_data_noise_data.csv'\n","df.to_csv(csv_file_path, index=False, encoding='utf-8')\n","\n","print(f\"sensor_data_ambient_noise CSV 파일이 성공적으로 저장되었습니다: {csv_file_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aKsrSzJnOErw","executionInfo":{"status":"ok","timestamp":1731580759128,"user_tz":-540,"elapsed":19465,"user":{"displayName":"남민주","userId":"08247165472229416741"}},"outputId":"75ded254-b104-4cc4-d3d8-8eed0e31d87a"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["sensor_data_ambient_noise CSV 파일이 성공적으로 저장되었습니다: /content/sensor_data_noise_data.csv\n"]}]},{"cell_type":"code","source":["import re\n","import pandas as pd\n","import chardet\n","\n","# SQL dump 파일 경로\n","sql_file_path = '/content/mqtt_server_humidity.sql'\n","\n","# 파일의 인코딩 자동 탐지\n","with open(sql_file_path, 'rb') as file:\n","    raw_data = file.read()\n","    result = chardet.detect(raw_data)\n","    encoding = result['encoding']\n","\n","# SQL dump 파일을 자동으로 감지된 인코딩 방식으로 읽기\n","with open(sql_file_path, 'r', encoding=encoding) as file:\n","    sql_script = file.read()\n","\n","# 'INSERT INTO' 구문을 찾기 위한 정규 표현식\n","insert_pattern = r\"INSERT INTO `sensor_data_humidity` VALUES \\((.*?)\\);\"\n","\n","# 모든 INSERT 구문을 추출\n","matches = re.findall(insert_pattern, sql_script)\n","\n","# 'sensor_data_humidity' 테이블에 대한 데이터 저장\n","data = []\n","\n","# 각 매치된 값에 대해 처리\n","for match in matches:\n","    # 개별 레코드를 나누기 위해 \"),\" 기준으로 분리 후 괄호 제거\n","    records = re.findall(r\"\\(([^)]+)\\)\", match)\n","    for record in records:\n","        # 개별 값들을 분리하여 리스트로 추가\n","        row = [x.strip().strip(\"'\") for x in record.split(',')]\n","        data.append(row)\n","\n","# 데이터 프레임 생성 및 CSV 파일로 저장\n","columns = ['id', 'sensor_id', 'timestamp', 'value']  # 적절한 열 이름으로 수정 가능\n","df = pd.DataFrame(data, columns=columns)\n","csv_file_path = '/content/sensor_data_humidity_data.csv'\n","df.to_csv(csv_file_path, index=False, encoding='utf-8')\n","\n","print(f\"sensor_data_humidity CSV 파일이 성공적으로 저장되었습니다: {csv_file_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3uj0bvuYQ3wh","executionInfo":{"status":"ok","timestamp":1731580957667,"user_tz":-540,"elapsed":50486,"user":{"displayName":"남민주","userId":"08247165472229416741"}},"outputId":"6a10a832-0d1d-42b8-a717-d3dc977504b0"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["sensor_data_humidity CSV 파일이 성공적으로 저장되었습니다: /content/sensor_data_humidity_data.csv\n"]}]}]}